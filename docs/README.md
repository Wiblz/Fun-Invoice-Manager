# File upload
I had to take some time to consider how file uploading should be implemented.
The first thought was to use a trivial approach, such as uploading the file to the server and storing it in a directory. However, upon reading the minio docs as well as finding out that "valet key" pattern is a goto approach for file uploading, I decided to go with the latter.

The valet key pattern is a pattern where the client is given a temporary URL to upload the file to. This URL is generated by the server and is only valid for a short period of time. This way, the server does not have to handle the file upload itself, and the client can upload the file directly to the storage, saving ingress and egress bandwidth.
After that I came to realization, that in order to use file hash as a filename, it (obviously) has to be calculated before the file is uploaded.
1. The client could calculate the hash and send it to the server, which would then generate the valet key and return it to the client. This introduces a problem: the client can never be trusted. The client could easily forge any file metadata, including the hash.
The possible solutions include using a temp environment for file uploads, then getting a file on backend and then perform any necessary validation. This obviously negates the benefits of the valet key pattern and is pointless.
2. The client just uploads the file to the server, and the server calculates the hash and generates the valet key. This is, essentially the trivial approach I was considering at the beginning.
However, the server doesn't have to store the file. After initial validation/processing is finished it can be removed from the server. A presigned URL can then be used by client to retrieve the file from the storage.

Eventually, I ended up going with the second approach. I don't see any other way to use a hash as a filename and avoiding trusting the client at the same time.
Considering that additional file processing is expected (extracting metadata, raw text, perhaps extracting some data with OCR or LLM), there's no avoiding uploading the file to our backend.
I am still using self-hosted minio server for file storage, and a minio client for file uploads. This makes it easy to switch to an actual S3 in production if needed.

## Content-Type
Turns out, MinIO (as well as S3) will serve the stored files with the same content-type as the one provided during the upload. `application/octet-stream` is used by default, which prevents PDFs from being embedded in the browser. This can be fixed by explicitly setting the content-type to `application/pdf` during the upload.

# Preventing duplicate uploads
There is a possible shortcut for checking if a file being uploaded is a duplicate.
The hash of the file can be calculated and checked against the database. If the hash is already present in the database, the file is a duplicate and can be discarded.
This is saving us from needing to request the file storage to make a duplicate check.

This, however, opens a possibility for a file storage to go out of sync with the database. If a file is uploaded, but the database is not updated, the file will bit be considered a duplicate on the next upload.
At the same time, if, for whatever reason the file is deleted from the storage, but the database is not updated, the file will be considered a duplicate on the next upload.
These edge cases could be pretty rare, but in the end I decided to go with the "safe" approach and always query the file storage for duplicates. This still does not prevent possible desyncs, but at least it makes the file storage the single source of truth.

## Client calculated invoice hash
The client calculates the hash of the invoice file and sends it to the server. The server then checks if the hash already exists in the database. If it does, the server responds with an error and the client prevents the form submission.
Exposing an endpoint for checking file existence by hash potentially allows an attacker to map the file storage contents.
This is not a concern in our use case, as the file storage is not meant to be private.

## Synchronizing the database with the file storage
On startup, the server checks the file storage for files that are not present in the database. These files are tagged as "missing" which can be seen in the frontend. This allows the user to see which files are missing and possibly reupload them later.  
I have a slight concern about the performance of this operation, as this queries all the filenames from the storage and also updated all the database entries. This could be a problem with a large number of files. However, I don't see any other way to keep the database in sync with the storage.
